{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cba8f607",
   "metadata": {
    "id": "cba8f607"
   },
   "source": [
    "# Flower Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ba4ab",
   "metadata": {
    "id": "605ba4ab"
   },
   "source": [
    "## [1] 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49c6c1f",
   "metadata": {
    "id": "e49c6c1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n"
     ]
    }
   ],
   "source": [
    "# 모듈 로딩\n",
    "import os\n",
    "print(os.listdir('C:/Users/ss/Downloads/archive/flowers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05078509",
   "metadata": {
    "id": "05078509"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    " \n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop,Adagrad\n",
    "\n",
    "from keras.layers import Dropout, Flatten,Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    " \n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "import cv2                  \n",
    "import numpy as np  \n",
    "\n",
    "from tqdm import tqdm # 진행률 프로세스바(반복되는 객체 tqdm() 감싸기)\n",
    "import os                   \n",
    "from random import shuffle  \n",
    "from zipfile import ZipFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ce1174",
   "metadata": {
    "id": "20ce1174"
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "Z=[]\n",
    "IMG_SIZE=150\n",
    "FLOWER_DAISY_DIR='C:/Users/ss/Downloads/archive/flowers/daisy'\n",
    "FLOWER_SUNFLOWER_DIR='C:/Users/ss/Downloads/archive/flowers/sunflower'\n",
    "FLOWER_TULIP_DIR='C:/Users/ss/Downloads/archive/flowers/tulip'\n",
    "FLOWER_DANDI_DIR='C:/Users/ss/Downloads/archive/flowers/dandelion'\n",
    "FLOWER_ROSE_DIR='C:/Users/ss/Downloads/archive/flowers/rose'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9788a519",
   "metadata": {
    "id": "9788a519"
   },
   "outputs": [],
   "source": [
    "# flower name 반환\n",
    "def assign_label(img,flower_type):\n",
    "    return flower_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3201d3d",
   "metadata": {
    "id": "e3201d3d"
   },
   "outputs": [],
   "source": [
    "# train 데이터 만들기\n",
    "def make_train_data(flower_type,DIR):\n",
    "    for img in tqdm(os.listdir(DIR), desc=flower_type):\n",
    "        label=assign_label(img,flower_type)\n",
    "        path = os.path.join(DIR,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR) # 경로, img파일 color로 불러들이기\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        \n",
    "        X.append(np.array(img))\n",
    "        Z.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c57ff",
   "metadata": {
    "id": "3f8c57ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Daisy:  55%|███████████████████████████████████████▊                                | 423/764 [00:00<00:00, 545.83it/s]"
     ]
    }
   ],
   "source": [
    "make_train_data('Daisy',FLOWER_DAISY_DIR)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40928fe",
   "metadata": {
    "id": "c40928fe"
   },
   "outputs": [],
   "source": [
    "make_train_data('Sunflower',FLOWER_SUNFLOWER_DIR)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bda650",
   "metadata": {
    "id": "b7bda650"
   },
   "outputs": [],
   "source": [
    "make_train_data('Tulip',FLOWER_TULIP_DIR)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798cd57f",
   "metadata": {
    "id": "798cd57f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_train_data('Dandelion',FLOWER_DANDI_DIR)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be90b6a2",
   "metadata": {
    "id": "be90b6a2"
   },
   "outputs": [],
   "source": [
    "make_train_data('Rose',FLOWER_ROSE_DIR)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97faf365",
   "metadata": {
    "id": "97faf365"
   },
   "source": [
    "### [1-1] Random Image 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9299ec08",
   "metadata": {
    "id": "9299ec08"
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(5,2)\n",
    "fig.set_size_inches(15,15)\n",
    "for i in range(5):\n",
    "    for j in range (2):\n",
    "        l=rn.randint(0,len(Z)) # 0~len(Z) 사이 난수 생성\n",
    "        ax[i,j].imshow(X[l])\n",
    "        ax[i,j].set_title('Flower: '+Z[l])\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca37e0",
   "metadata": {
    "id": "13ca37e0"
   },
   "source": [
    "## [2] 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c96aa0f",
   "metadata": {
    "id": "3c96aa0f"
   },
   "source": [
    "### [2-1] OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d15ff6",
   "metadata": {
    "id": "78d15ff6"
   },
   "outputs": [],
   "source": [
    "OHE = OneHotEncoder(sparse=False)\n",
    "Z = np.array(Z).reshape(-1,1)\n",
    "Y = OHE.fit_transform(Z)\n",
    "# X numpy 배열로 변경, 스케일링\n",
    "X = np.array(X)\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c5de50",
   "metadata": {
    "id": "78c5de50"
   },
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b197d1",
   "metadata": {
    "id": "58b197d1"
   },
   "source": [
    "### [2-2] 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787858f0",
   "metadata": {
    "id": "787858f0"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa0aea",
   "metadata": {
    "id": "8bfa0aea"
   },
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02147e61",
   "metadata": {
    "id": "02147e61"
   },
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f824f",
   "metadata": {
    "id": "4c0f824f"
   },
   "source": [
    "### [2-3] Random seed Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22601bdd",
   "metadata": {
    "id": "22601bdd"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rn.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc9494",
   "metadata": {
    "id": "cfbc9494"
   },
   "source": [
    "## [3] 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977e6c3d",
   "metadata": {
    "id": "977e6c3d"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (150,150,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    " \n",
    "model.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbe4adc",
   "metadata": {
    "id": "0bbe4adc"
   },
   "source": [
    "### [3-1] ReduceLROnPlateau(callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da8b23",
   "metadata": {
    "id": "92da8b23"
   },
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "epochs=43\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "red_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a210f0f",
   "metadata": {
    "id": "8a210f0f"
   },
   "source": [
    "### [3-2] 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da2275",
   "metadata": {
    "id": "29da2275"
   },
   "outputs": [],
   "source": [
    "# CNN 모델의 성능을 높이면서 오버피팅을 극복할 수 있는 가장 좋고 근본적인 해결책은 학습 데이터의 다양성을 늘리는 것\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False,  \n",
    "        zca_whitening=False,  \n",
    "        rotation_range=45,  # 회전반경 45도 이내 설정\n",
    "        zoom_range = 0.1, # 확대 범위 \n",
    "        width_shift_range=0.2,  # 너비 반경 20%\n",
    "        height_shift_range=0.2,  # 높이 반경 20%\n",
    "        horizontal_flip=True,  # 수평반전\n",
    "        vertical_flip=True)  # 수직반전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cbed66",
   "metadata": {
    "id": "e6cbed66"
   },
   "outputs": [],
   "source": [
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8dc79",
   "metadata": {
    "id": "4be8dc79"
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5338d609",
   "metadata": {
    "id": "5338d609"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c5fda3",
   "metadata": {
    "id": "91c5fda3"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3STRgdl55HFt",
   "metadata": {
    "id": "3STRgdl55HFt"
   },
   "source": [
    "## [4] 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac104d34",
   "metadata": {
    "id": "ac104d34",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (x_val,y_val),\n",
    "                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9306865",
   "metadata": {
    "id": "b9306865"
   },
   "outputs": [],
   "source": [
    "epochs = [i for i in range(43)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = History.history['accuracy']\n",
    "train_loss = History.history['loss']\n",
    "val_acc = History.history['val_accuracy']\n",
    "val_loss = History.history['val_loss']\n",
    "fig.set_size_inches(20,10)\n",
    "\n",
    "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
    "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Val Accuracy')\n",
    "ax[0].set_title('Training & Val Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\n",
    "ax[1].plot(epochs , val_loss , 'r-o' , label = 'Val Loss')\n",
    "ax[1].set_title('Training & Val Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KbwvzohV5UnZ",
   "metadata": {
    "id": "KbwvzohV5UnZ"
   },
   "source": [
    "## [5] 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iAukzhOF72z-",
   "metadata": {
    "id": "iAukzhOF72z-"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "np.round(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eHvhb-X3_Niw",
   "metadata": {
    "id": "eHvhb-X3_Niw"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c48195c",
   "metadata": {},
   "source": [
    "### [5-1] test data 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yXL7Sss38p4A",
   "metadata": {
    "id": "yXL7Sss38p4A",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# daisy,sunflower,tulip,dandelion,rose\n",
    "for i in range(0,10):\n",
    "  l=rn.randint(0,x_test.shape[0])\n",
    "  plt.imshow(x_test[l].reshape(150,150,3))\n",
    "  if int(np.round(pred[l])[1]) == 1:\n",
    "      plt.title(f'Prediction Result : {np.round(pred[l])} : dandelion')\n",
    "  elif int(np.round(pred[l])[0]) == 1:\n",
    "      plt.title(f'Prediction Result : {np.round(pred[l])} : daisy')\n",
    "  elif int(np.round(pred[l])[2]) == 1:\n",
    "      plt.title(f'Prediction Result : {np.round(pred[l])} : rose')\n",
    "  elif int(np.round(pred[l])[3]) == 1:\n",
    "      plt.title(f'Prediction Result : {np.round(pred[l])} : sunflower')\n",
    "  else:\n",
    "    plt.title(f'Prediction Result : {np.round(pred[l])} : tulip')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k8biL1BZgQC7",
   "metadata": {
    "id": "k8biL1BZgQC7"
   },
   "outputs": [],
   "source": [
    "pre_test = []\n",
    "for img in os.listdir('C:/Users/ss/Desktop/flower_test'):\n",
    "        \n",
    "        path = os.path.join('C:/Users/ss/Desktop/flower_test',img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR) # 경로, img파일 color로 불러들이기\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (150,150))\n",
    "        pre_test.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98oss8OjyalP",
   "metadata": {
    "id": "98oss8OjyalP"
   },
   "outputs": [],
   "source": [
    "model.predict(pre_test[0].reshape(-1,150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ivSbkP8d2Moa",
   "metadata": {
    "id": "ivSbkP8d2Moa"
   },
   "outputs": [],
   "source": [
    "np.round(model.predict(pre_test[0].reshape(-1,150,150,3)))[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf742e1",
   "metadata": {},
   "source": [
    "### [5-2] 임의의 image 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dPZxucezqnm",
   "metadata": {
    "id": "8dPZxucezqnm",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "  test = np.round(model.predict(pre_test[i].reshape(-1,150,150,3)))\n",
    "  if int(test[0][0]) == 1:\n",
    "    plt.imshow(pre_test[i])\n",
    "    plt.title('daisy')\n",
    "  \n",
    "  elif int(test[0][1]) == 1:\n",
    "    plt.imshow(pre_test[i])\n",
    "    plt.title('dandelion')\n",
    "\n",
    "  elif int(test[0][2]) == 1:\n",
    "    plt.imshow(pre_test[i])\n",
    "    plt.title('rose')\n",
    "  \n",
    "  elif int(test[0][3]) == 1:\n",
    "    plt.imshow(pre_test[i])\n",
    "    plt.title('sunflower')\n",
    "  \n",
    "  else:\n",
    "    plt.imshow(pre_test[i])\n",
    "    plt.title('tulip')\n",
    "    \n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
